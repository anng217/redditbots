{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose comments within 60 days of bot implementation\n",
    "def within_60days(df,year,month,day):\n",
    "    after = int((dt.datetime(year=year,month=month,day=day)-dt.timedelta(days = 30)).timestamp())\n",
    "    before = int((dt.datetime(year=year,month=month,day=day)+dt.timedelta(days = 30)).timestamp()) \n",
    "    res = df[(df['created_utc'] >=  after) & (df['created_utc'] <= before)] #need to check again\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comm_report(df):\n",
    "    #print no of comments\n",
    "    print(f'This df originally has {len(df)} comments.')\n",
    "    \n",
    "    #print num of pre and post\n",
    "    num_pre = len(df[df['post']==0])\n",
    "    num_post = len(df[df['post']==1])\n",
    "    print(f'Pre:{num_pre}, Post:{num_post}')\n",
    "\n",
    "    #print no of del comments\n",
    "    num_del = len(df[(df['body'] == '[deleted]') | (df['body'] == '[removed]')])\n",
    "    print(f'{num_del} comments were deleted/removed.')\n",
    "\n",
    "    #print comments by AutoMod\n",
    "    num_automod = len(df[df['author'] =='AutoModerator'])\n",
    "    print(f'Automod posted {num_automod} comments.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subm_report(df):\n",
    "    #print num of sub\n",
    "    print(f'This df has {len(df)} submissions.')\n",
    "\n",
    "    #print num of pre and post\n",
    "    num_pre = len(df[df['post']==0])\n",
    "    num_post = len(df[df['post']==1])\n",
    "    print(f'Pre:{num_pre}, Post:{num_post}')\n",
    "\n",
    "    #print subm blank\n",
    "    num_null = len(df[df['selftext'].notna()])\n",
    "    print(f'{num_null} submissions has content')\n",
    "\n",
    "    #print no of del submissions\n",
    "    num_del = len(df[(df['selftext'] == '[deleted]') | (df['selftext'] == '[removed]')])\n",
    "    print(f'{num_del} comments were deleted or removed.')\n",
    "\n",
    "    #print subm by AutoMod\n",
    "    num_automod = len(df[df['author'] =='AutoModerator'])\n",
    "    print(f'Automod posted {num_automod} submissions.')\n",
    "\n",
    "    #print subm is meme\n",
    "    num_meme_pre = len(df[((df['domain'] == 'i.redd.it') | (df['domain'] == 'i.imgur.com') | (df['domain'] == 'imgur.com')) & (df['post']==0)])\n",
    "    print(f'{num_meme_pre} submissions are images pre.')\n",
    "    \n",
    "    num_meme_post = len(df[((df['domain'] == 'i.redd.it') | (df['domain'] == 'i.imgur.com') | (df['domain'] == 'imgur.com')) & (df['post']==1)])\n",
    "    print(f'{num_meme_post} submissions are images post.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_comments(source_dir,save_dir,year,month,day):\n",
    "    df = pd.read_csv(source_dir)\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    #read files and choose relevant vars\n",
    "    df = df.reindex(columns = ['body','author','created_utc','retrieved_on','permalink','parent_id','subreddit','score','post'])\n",
    "    df = df[['body','author','created_utc','retrieved_on','permalink','parent_id','subreddit','score','post']]\n",
    "\n",
    "    #filter comments within 60 days of bot implementation\n",
    "    df = within_60days(df=df,year=year,month=month,day=day)\n",
    "\n",
    "    #change epoch time to human time\n",
    "    df['created_utc'] = pd.to_datetime(df['created_utc'], unit='s')\n",
    "    df['retrieved_on'] = pd.to_datetime(df['retrieved_on'], unit='s')\n",
    "    df['updated_utc'] = pd.to_datetime(df['retrieved_on'], unit='s')\n",
    "    \n",
    "    #print numbers\n",
    "    comm_report(df)\n",
    "\n",
    "    #filter out deleted and removed comments\n",
    "    df = df[(df['body'] != '[deleted]') & (df['body'] != '[removed]') & (df['author'] !='AutoModerator')]\n",
    "\n",
    "    #moare report\n",
    "    num_case(df)\n",
    "\n",
    "    #write csv\n",
    "    df.to_csv(save_dir,encoding = 'utf-8-sig')\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_subm(source_dir,save_dir,year,month,day):\n",
    "    df = pd.read_csv(source_dir)\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    #read files and choose relevant vars\n",
    "    df = df.reindex(columns = ['author','author_flair_text','created_utc','retrieved_on','domain','full_link','id','is_reddit_media_domain','permalink','is_video','locked','num_comments','subreddit','subreddit_id','score','selftext','subreddit_subscribers','title','total_awards_received','updated_utc','removed_by','poll_data','post'])\n",
    "    df = df[['author','author_flair_text','created_utc','retrieved_on','domain','full_link','id','is_reddit_media_domain','permalink','is_video','locked','num_comments','subreddit','subreddit_id','score','selftext','subreddit_subscribers','title','total_awards_received','updated_utc','removed_by','poll_data','post']]\n",
    "\n",
    "    #filter comments within 60 days of bot implementation\n",
    "    df = within_60days(df=df,year=year,month=month,day=day)\n",
    "\n",
    "    #print numbers\n",
    "    subm_report(df)\n",
    "\n",
    "    #filter out deleted and removed comments\n",
    "    df = df[(df['selftext'] != '[deleted]') & (df['selftext'] != '[removed]')]\n",
    "    df = df[(df['author'] !='AutoModerator')]\n",
    "    df = df[(df['domain'] != 'i.redd.it') & (df['domain'] != 'i.imgur.com') &  (df['domain'] != 'imgur.com')]\n",
    "    df = df[df['selftext'].notna()]\n",
    "\n",
    "    #change epoch time to human time\n",
    "    df['created_utc'] = pd.to_datetime(df['created_utc'], unit='s')\n",
    "    df['retrieved_on'] = pd.to_datetime(df['retrieved_on'], unit='s')\n",
    "\n",
    "    #moare report\n",
    "    num_case(df)\n",
    "\n",
    "    #write csv\n",
    "    df.to_csv(save_dir,encoding = 'utf-8-sig')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_case(df):\n",
    "    num_post = len(df[df['post']==1])\n",
    "    num_pre = len(df[df['post']==0])\n",
    "    print(f'Pre: {num_pre}, Post: {num_post}, Total: {num_pre+num_post}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply to subr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## r/exfds\n",
    "Nov 23 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This df originally has 600 comments.\n",
      "Pre:468, Post:132\n",
      "21 comments were deleted/removed.\n",
      "Automod posted 0 comments.\n",
      "Post: 127, Pre: 452, Total: 579\n"
     ]
    }
   ],
   "source": [
    "exfds_comments = clean_comments(source_dir = './data/exfds/exfds_comments.csv', save_dir = './data/exfds/exfds_clean_comments.csv', year = 2020, month = 11, day =23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This df has 47 submissions.\n",
      "Pre:35, Post:12\n",
      "27 submissions has content\n",
      "7 comments were deleted or removed.\n",
      "Automod posted 0 submissions.\n",
      "10 submissions are images pre.\n",
      "3 submissions are images post.\n",
      "Post: 5, Pre: 15, Total: 20\n"
     ]
    }
   ],
   "source": [
    "exfds_subm = clean_subm(source_dir = './data/exfds/exfds_subm.csv', save_dir = './data/exfds/exfds_clean_subm.csv', year = 2020, month = 11, day =23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# r/WitchesVSPatriarchy\n",
    "\n",
    "Dec 22, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nguye\\AppData\\Local\\Temp\\ipykernel_9716\\1733050532.py:2: DtypeWarning: Columns (38,39,40,41,43,47,48,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(source_dir)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This df originally has 43894 comments.\n",
      "Pre:23015, Post:20879\n",
      "9560 comments were deleted/removed.\n",
      "Automod posted 0 comments.\n",
      "Post: 15610, Pre: 18724, Total: 34334\n"
     ]
    }
   ],
   "source": [
    "wvsp_comments = clean_comments(source_dir = './data/witchesvspatriarchy/wvsp_comments.csv', save_dir = './data/exfds/wvsp_clean_comments.csv', year = 2020, month = 12, day =22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This df has 3075 submissions.\n",
      "Pre:1664, Post:1411\n",
      "664 submissions has content\n",
      "251 comments were deleted or removed.\n",
      "Automod posted 0 submissions.\n",
      "1004 submissions are images pre.\n",
      "894 submissions are images post.\n",
      "Pre: 238, Post: 175, Total: 413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nguye\\AppData\\Local\\Temp\\ipykernel_9716\\1365198384.py:2: DtypeWarning: Columns (78,80,82,83) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(source_dir)\n"
     ]
    }
   ],
   "source": [
    "wvsp_subm = clean_subm(source_dir = './data/witchesvspatriarchy/wvsp_subm.csv', save_dir = './data/exfds/wvsp_clean_subm.csv', year = 2020, month = 12, day =22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual as reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fds_comments_after = pd.read_csv('./data/fds_comments_after.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only choose what relevant\n",
    "fds_comments_after_df = fds_comments_after[['body','author','created_utc','retrieved_on','permalink','parent_id','subreddit','score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change epoch time to human time \n",
    "fds_comments_after_df['created_utc'] = pd.to_datetime(fds_comments_after_df['created_utc'], unit='s')\n",
    "fds_comments_after_df['retrieved_on'] = pd.to_datetime(fds_comments_after_df['retrieved_on'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get month (Oct and Nov)\n",
    "# Two conditions, to check if data is what I want\n",
    "fds_comments_after_df[(fds_comments_after_df['created_utc'].dt.month == 10) & (fds_comments_after_df['created_utc'].dt.day == 28)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get month (Oct and Nov) - 1 mo after bot; Dec - 2 mo after bot; Jan - 3 mo after bot\n",
    "fds_comments_after_1mo_df = fds_comments_after_df[(fds_comments_after_df['created_utc'].dt.month == 10) | (fds_comments_after_df['created_utc'].dt.month == 11)]\n",
    "fds_comments_after_2mo_df = fds_comments_after_df[fds_comments_after_df['created_utc'].dt.month == 12]\n",
    "fds_comments_after_3mo_df = fds_comments_after_df[fds_comments_after_df['created_utc'].dt.month == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save datasets\n",
    "fds_comments_after_1mo_df.to_csv('fds_comments_after_1mo.csv')\n",
    "fds_comments_after_2mo_df.to_csv('fds_comments_after_2mo.csv')\n",
    "fds_comments_after_3mo_df.to_csv('fds_comments_after_3mo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before comments\n",
    "Replicate the steps above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fds_comments_before = pd.read_csv('fds_comments_before.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fds_comments_before_df = fds_comments_before[['body','author','created_utc','retrieved_on','permalink','parent_id','subreddit','score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change epoch time to human time \n",
    "fds_comments_before_df['created_utc'] = pd.to_datetime(fds_comments_before_df['created_utc'], unit='s')\n",
    "fds_comments_before_df['retrieved_on'] = pd.to_datetime(fds_comments_before_df['retrieved_on'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the date range is what I want\n",
    "fds_comments_before_df[(fds_comments_before_df['created_utc'].dt.month == 10) & (fds_comments_before_df['created_utc'].dt.day == 27)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get month\n",
    "fds_comments_before_1mo_df = fds_comments_after_df[fds_comments_after_df['created_utc'].dt.month == 10]\n",
    "fds_comments_before_2mo_df = fds_comments_after_df[fds_comments_after_df['created_utc'].dt.month == 9]\n",
    "fds_comments_before_3mo_df = fds_comments_after_df[fds_comments_after_df['created_utc'].dt.month == 8]\n",
    "fds_comments_before_4mo_df = fds_comments_after_df[fds_comments_after_df['created_utc'].dt.month == 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save datasets\n",
    "fds_comments_before_1mo_df.to_csv('fds_comments_before_1mo.csv')\n",
    "fds_comments_before_2mo_df.to_csv('fds_comments_before_2mo.csv')\n",
    "fds_comments_before_3mo_df.to_csv('fds_comments_before_3mo.csv')\n",
    "fds_comments_before_4mo_df.to_csv('fds_comments_before_4mo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fds_sub_b4 = pd.read_csv('./data/fds_submissions_before.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fds_sub_b4_df = fds_sub_b4[['author','author_flair_text','created_utc','retrieved_on','domain','full_link','id','is_reddit_media_domain','permalink','is_video','locked','num_comments','subreddit','subreddit_id','score','selftext','subreddit_subscribers','title','total_awards_received','updated_utc','removed_by','poll_data']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to human date\n",
    "fds_sub_b4_df['created_utc'] = pd.to_datetime(fds_sub_b4_df['created_utc'], unit='s')\n",
    "fds_sub_b4_df['retrieved_on'] = pd.to_datetime(fds_sub_b4_df['retrieved_on'], unit='s')\n",
    "fds_sub_b4_df['updated_utc'] = pd.to_datetime(fds_sub_b4_df['updated_utc'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the date range is what I want\n",
    "fds_sub_b4_df[(fds_sub_b4_df['created_utc'].dt.month == 7) & (fds_sub_b4_df['created_utc'].dt.day == 27)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get month\n",
    "fds_subm_before_1mo_df = fds_sub_b4_df[fds_sub_b4_df['created_utc'].dt.month == 10]\n",
    "fds_subm_before_2mo_df = fds_sub_b4_df[fds_sub_b4_df['created_utc'].dt.month == 9]\n",
    "fds_subm_before_3mo_df = fds_sub_b4_df[fds_sub_b4_df['created_utc'].dt.month == 8]\n",
    "fds_subm_before_4mo_df = fds_sub_b4_df[fds_sub_b4_df['created_utc'].dt.month == 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save datasets\n",
    "fds_subm_before_1mo_df.to_csv('./data/fds_subm_before_1mo.csv')\n",
    "fds_subm_before_2mo_df.to_csv('./data/fds_subm_before_2mo.csv')\n",
    "fds_subm_before_3mo_df.to_csv('./data/fds_subm_before_3mo.csv')\n",
    "fds_subm_before_4mo_df.to_csv('./data/fds_subm_before_4mo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submissions after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fds_sub_after = pd.read_csv('./data/fds_submissions_after.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fds_sub_after_df = fds_sub_after[['author','author_flair_text','created_utc','retrieved_on','domain','full_link','id','is_reddit_media_domain','permalink','is_video','locked','num_comments','subreddit','subreddit_id','score','selftext','subreddit_subscribers','title','total_awards_received','updated_utc','removed_by']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to human date\n",
    "fds_sub_after_df['created_utc'] = pd.to_datetime(fds_sub_after_df['created_utc'], unit='s')\n",
    "fds_sub_after_df['retrieved_on'] = pd.to_datetime(fds_sub_after_df['retrieved_on'], unit='s')\n",
    "fds_sub_after_df['updated_utc'] = pd.to_datetime(fds_sub_after_df['updated_utc'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fds_sub_after_df[(fds_sub_after_df['created_utc'].dt.month == 10) & (fds_sub_after_df['created_utc'].dt.day == 28)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get month\n",
    "fds_subm_after_1mo_df = fds_sub_after_df[(fds_sub_after_df['created_utc'].dt.month == 11) &(fds_sub_after_df['created_utc'].dt.month == 10)]\n",
    "fds_subm_after_2mo_df = fds_sub_after_df[fds_sub_after_df['created_utc'].dt.month == 12]\n",
    "fds_subm_after_3mo_df = fds_sub_after_df[fds_sub_after_df['created_utc'].dt.month == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save datasets\n",
    "fds_subm_after_1mo_df.to_csv('./data/fds_subm_after_1mo.csv')\n",
    "fds_subm_after_2mo_df.to_csv('./data/fds_subm_after_2mo.csv')\n",
    "fds_subm_after_3mo_df.to_csv('./data/fds_subm_after_3mo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Analysis\n",
    "For Comments: Deleted comments\n",
    "\n",
    "For Submissions: Deleted submissions, non-text content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import BEFORE data. Dataset already in this notebook\n",
    "fds_b4_1mo =  pd.read_csv('./data/fds_comments_before_1mo.csv')\n",
    "\n",
    "#Number of deleted and remove\n",
    "len(fds_b4_1mo[(fds_b4_1mo['body'] == '[deleted]') | (fds_b4_1mo['body'] == '[removed]')])/len(fds_b4_1mo)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import AFTER data\n",
    "fds_aft_1mo =  pd.read_csv('./data/fds_comments_after_1mo.csv')\n",
    "\n",
    "#Number of deleted and remove\n",
    "len(fds_aft_1mo[(fds_aft_1mo['body'] == '[deleted]') | (fds_aft_1mo['body'] == '[removed]')])/len(fds_aft_1mo)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of deleted commments - Other months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import BEFORE data - Jul\n",
    "fds_jul =  pd.read_csv('./data/fds_comments_before_4mo.csv')\n",
    "\n",
    "#Number of deleted and remove\n",
    "len(fds_jul[(fds_jul['body'] == '[deleted]') | (fds_jul['body'] == '[removed]')])/len(fds_jul)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import BEFORE data - Aug\n",
    "fds_aug =  pd.read_csv('./data/fds_comments_before_3mo.csv')\n",
    "\n",
    "#Number of deleted and remove\n",
    "len(fds_aug[(fds_aug['body'] == '[deleted]') | (fds_aug['body'] == '[removed]')])/len(fds_aug)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import BEFORE data - Sep\n",
    "fds_sep =  pd.read_csv('./data/fds_comments_before_2mo.csv')\n",
    "\n",
    "#Number of deleted and remove\n",
    "len(fds_sep[(fds_sep['body'] == '[deleted]') | (fds_sep['body'] == '[removed]')])/len(fds_sep)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import AFTER data - Dec\n",
    "fds_dec =  pd.read_csv('./data/fds_comments_after_2mo.csv')\n",
    "\n",
    "#Number of deleted and remove\n",
    "len(fds_dec[(fds_dec['body'] == '[deleted]') | (fds_dec['body'] == '[removed]')])/len(fds_dec)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import AFTER data - Jan\n",
    "fds_jan =  pd.read_csv('./data/fds_comments_after_3mo.csv')\n",
    "\n",
    "#Number of deleted and remove\n",
    "len(fds_jan[(fds_jan['body'] == '[deleted]') | (fds_jan['body'] == '[removed]')])/len(fds_jan)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redditbots",
   "language": "python",
   "name": "redditbots"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b968dbae3bdbf6d1cce176bc5e29e5d5d95fd8d61e6698691c9965b2a654e88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
