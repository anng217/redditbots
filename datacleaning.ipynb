{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose comments within 60 days of bot implementation\n",
    "def within_60days(df,year,month,day):\n",
    "    after = int((dt.datetime(year=year,month=month,day=day)-dt.timedelta(days = 30)).timestamp())\n",
    "    before = int((dt.datetime(year=year,month=month,day=day)+dt.timedelta(days = 30)).timestamp()) \n",
    "    res = df[(df['created_utc'] >=  after) & (df['created_utc'] <= before)] #need to check again\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comm_report(df):\n",
    "    #print no of comments\n",
    "    print(f'This df originally has {len(df)} comments.')\n",
    "    \n",
    "    #print num of pre and post\n",
    "    num_pre = len(df[df['post']==0])\n",
    "    num_post = len(df[df['post']==1])\n",
    "    print(f'Pre:{num_pre}, Post:{num_post}')\n",
    "\n",
    "    #print no of del comments\n",
    "    num_del = len(df[(df['body'] == '[deleted]') | (df['body'] == '[removed]')])\n",
    "    print(f'{num_del} comments were deleted/removed.')\n",
    "\n",
    "    #print comments by AutoMod\n",
    "    num_automod = len(df[df['author'] =='AutoModerator'])\n",
    "    print(f'Automod posted {num_automod} comments.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subm_report(df):\n",
    "    #print num of sub\n",
    "    print(f'This df has {len(df)} submissions.')\n",
    "\n",
    "    #print num of pre and post\n",
    "    num_pre = len(df[df['post']==0])\n",
    "    num_post = len(df[df['post']==1])\n",
    "    print(f'Pre:{num_pre}, Post:{num_post}')\n",
    "\n",
    "    #print subm blank\n",
    "    num_null = len(df[df['selftext'].notna()])\n",
    "    print(f'{num_null} submissions has content')\n",
    "\n",
    "    #print no of del submissions\n",
    "    num_del = len(df[(df['selftext'] == '[deleted]') | (df['selftext'] == '[removed]')])\n",
    "    print(f'{num_del} comments were deleted or removed.')\n",
    "\n",
    "    #print subm by AutoMod\n",
    "    num_automod = len(df[df['author'] =='AutoModerator'])\n",
    "    print(f'Automod posted {num_automod} submissions.')\n",
    "\n",
    "    #print subm is meme\n",
    "    num_meme_pre = len(df[((df['domain'] == 'i.redd.it') | (df['domain'] == 'i.imgur.com') | (df['domain'] == 'imgur.com')) & (df['post']==0)])\n",
    "    print(f'{num_meme_pre} submissions are images pre.')\n",
    "    \n",
    "    num_meme_post = len(df[((df['domain'] == 'i.redd.it') | (df['domain'] == 'i.imgur.com') | (df['domain'] == 'imgur.com')) & (df['post']==1)])\n",
    "    print(f'{num_meme_post} submissions are images post.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_comments(source_dir,save_dir,year,month,day):\n",
    "    df = pd.read_csv(source_dir)\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    #read files and choose relevant vars\n",
    "    df = df.reindex(columns = ['body','author','created_utc','retrieved_on','permalink','parent_id','subreddit','subreddit_subscribers','score','post'])\n",
    "    df = df[['body','author','created_utc','retrieved_on','permalink','parent_id','subreddit','subreddit_subscribers','score','post']]\n",
    "\n",
    "    #filter comments within 60 days of bot implementation\n",
    "    df = within_60days(df=df,year=year,month=month,day=day)\n",
    "\n",
    "    #change epoch time to human time\n",
    "    df['created_utc'] = pd.to_datetime(df['created_utc'], unit='s')\n",
    "    df['retrieved_on'] = pd.to_datetime(df['retrieved_on'], unit='s')\n",
    "    df['updated_utc'] = pd.to_datetime(df['retrieved_on'], unit='s')\n",
    "    \n",
    "    #print numbers\n",
    "    comm_report(df)\n",
    "\n",
    "    #filter out deleted and removed comments\n",
    "    df = df[(df['body'] != '[deleted]') & (df['body'] != '[removed]') & (df['author'] !='AutoModerator')]\n",
    "\n",
    "    #moare report\n",
    "    num_case(df)\n",
    "\n",
    "    #write csv\n",
    "    df.to_csv(save_dir,encoding = 'utf-8-sig')\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_subm(source_dir,save_dir,year,month,day):\n",
    "    df = pd.read_csv(source_dir)\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    #read files and choose relevant vars\n",
    "    df = df.reindex(columns = ['author','author_flair_text','created_utc','retrieved_on','domain','full_link','id','is_reddit_media_domain','permalink','is_video','locked','num_comments','subreddit','subreddit_id','score','selftext','subreddit_subscribers','title','total_awards_received','updated_utc','removed_by','poll_data','post'])\n",
    "    df = df[['author','author_flair_text','created_utc','retrieved_on','domain','full_link','id','is_reddit_media_domain','permalink','is_video','locked','num_comments','subreddit','subreddit_id','score','selftext','subreddit_subscribers','title','total_awards_received','updated_utc','removed_by','poll_data','post']]\n",
    "\n",
    "    #filter comments within 60 days of bot implementation\n",
    "    df = within_60days(df=df,year=year,month=month,day=day)\n",
    "\n",
    "    #print numbers\n",
    "    subm_report(df)\n",
    "\n",
    "    #filter out deleted and removed comments\n",
    "    df = df[(df['selftext'] != '[deleted]') & (df['selftext'] != '[removed]')]\n",
    "    df = df[(df['author'] !='AutoModerator')]\n",
    "    df = df[(df['domain'] != 'i.redd.it') & (df['domain'] != 'i.imgur.com') &  (df['domain'] != 'imgur.com')]\n",
    "    df = df[df['selftext'].notna()]\n",
    "\n",
    "    #change epoch time to human time\n",
    "    df['created_utc'] = pd.to_datetime(df['created_utc'], unit='s')\n",
    "    df['retrieved_on'] = pd.to_datetime(df['retrieved_on'], unit='s')\n",
    "\n",
    "    #moare report\n",
    "    num_case(df)\n",
    "\n",
    "    #write csv\n",
    "    df.to_csv(save_dir,encoding = 'utf-8-sig')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_case(df):\n",
    "    num_post = len(df[df['post']==1])\n",
    "    num_pre = len(df[df['post']==0])\n",
    "    print(f'Pre: {num_pre}, Post: {num_post}, Total: {num_pre+num_post}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply to subr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## r/exfds\n",
    "Nov 23 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This df originally has 600 comments.\n",
      "Pre:468, Post:132\n",
      "21 comments were deleted/removed.\n",
      "Automod posted 0 comments.\n",
      "Post: 127, Pre: 452, Total: 579\n"
     ]
    }
   ],
   "source": [
    "exfds_comments = clean_comments(source_dir = './data/exfds/exfds_comments.csv', save_dir = './data/exfds/exfds_clean_comments.csv', year = 2020, month = 11, day =23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This df has 47 submissions.\n",
      "Pre:35, Post:12\n",
      "27 submissions has content\n",
      "7 comments were deleted or removed.\n",
      "Automod posted 0 submissions.\n",
      "10 submissions are images pre.\n",
      "3 submissions are images post.\n",
      "Post: 5, Pre: 15, Total: 20\n"
     ]
    }
   ],
   "source": [
    "exfds_subm = clean_subm(source_dir = './data/exfds/exfds_subm.csv', save_dir = './data/exfds/exfds_clean_subm.csv', year = 2020, month = 11, day =23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## r/WitchesVSPatriarchy\n",
    "\n",
    "Dec 22, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nguye\\AppData\\Local\\Temp\\ipykernel_9716\\1733050532.py:2: DtypeWarning: Columns (38,39,40,41,43,47,48,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(source_dir)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This df originally has 43894 comments.\n",
      "Pre:23015, Post:20879\n",
      "9560 comments were deleted/removed.\n",
      "Automod posted 0 comments.\n",
      "Post: 15610, Pre: 18724, Total: 34334\n"
     ]
    }
   ],
   "source": [
    "wvsp_comments = clean_comments(source_dir = './data/witchesvspatriarchy/wvsp_comments.csv', save_dir = './data/exfds/wvsp_clean_comments.csv', year = 2020, month = 12, day =22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This df has 3075 submissions.\n",
      "Pre:1664, Post:1411\n",
      "664 submissions has content\n",
      "251 comments were deleted or removed.\n",
      "Automod posted 0 submissions.\n",
      "1004 submissions are images pre.\n",
      "894 submissions are images post.\n",
      "Pre: 238, Post: 175, Total: 413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nguye\\AppData\\Local\\Temp\\ipykernel_9716\\1365198384.py:2: DtypeWarning: Columns (78,80,82,83) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(source_dir)\n"
     ]
    }
   ],
   "source": [
    "wvsp_subm = clean_subm(source_dir = './data/witchesvspatriarchy/wvsp_subm.csv', save_dir = './data/exfds/wvsp_clean_subm.csv', year = 2020, month = 12, day =22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## r/wgtow\n",
    "Apr 29, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This df originally has 2127 comments.\n",
      "Pre:842, Post:1285\n",
      "131 comments were deleted/removed.\n",
      "Automod posted 69 comments.\n",
      "Pre: 763, Post: 1164, Total: 1927\n"
     ]
    }
   ],
   "source": [
    "wgtow_com = clean_comments(source_dir='./data/wgtow/wgtow_comments.csv', save_dir = './data/wgtow/wgtow_clean_comments.csv', year = 2021, month = 4, day = 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This df has 222 submissions.\n",
      "Pre:87, Post:135\n",
      "151 submissions has content\n",
      "7 comments were deleted or removed.\n",
      "Automod posted 49 submissions.\n",
      "7 submissions are images pre.\n",
      "22 submissions are images post.\n",
      "Pre: 34, Post: 61, Total: 95\n"
     ]
    }
   ],
   "source": [
    "wgtow_sub = clean_subm(source_dir='./data/wgtow/wgtow_subm.csv', save_dir = './data/wgtow/wgtow_clean_subm.csv', year = 2021, month = 4, day = 29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## r/feminisms\n",
    "Mar 17, 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This df originally has 2440 comments.\n",
      "Pre:1288, Post:1152\n",
      "635 comments were deleted/removed.\n",
      "Automod posted 0 comments.\n",
      "Pre: 906, Post: 899, Total: 1805\n"
     ]
    }
   ],
   "source": [
    "fem_com = clean_comments(source_dir='./data/feminisms/fems_comments.csv', save_dir = './data/feminisms/fems_clean_comments.csv', year = 2012, month = 3, day = 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This df has 572 submissions.\n",
      "Pre:328, Post:244\n",
      "35 submissions has content\n",
      "0 comments were deleted or removed.\n",
      "Automod posted 0 submissions.\n",
      "4 submissions are images pre.\n",
      "5 submissions are images post.\n",
      "Pre: 19, Post: 16, Total: 35\n"
     ]
    }
   ],
   "source": [
    "fem_subm = clean_subm(source_dir='./data/feminisms/fems_subm.csv', save_dir = './data/feminisms/fems_clean_subm.csv', year = 2012, month = 3, day = 17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## r/women\n",
    "June 27, 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This df originally has 472 comments.\n",
      "Pre:271, Post:201\n",
      "104 comments were deleted/removed.\n",
      "Automod posted 0 comments.\n",
      "Pre: 214, Post: 154, Total: 368\n"
     ]
    }
   ],
   "source": [
    "women_comm = clean_comments(source_dir='./data/women/women_comments.csv', save_dir = './data/women/women_clean_comments.csv', year = 2016, month = 6, day = 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This df has 1232 submissions.\n",
      "Pre:550, Post:682\n",
      "238 submissions has content\n",
      "212 comments were deleted or removed.\n",
      "Automod posted 0 submissions.\n",
      "11 submissions are images pre.\n",
      "7 submissions are images post.\n",
      "Pre: 15, Post: 11, Total: 26\n"
     ]
    }
   ],
   "source": [
    "women_subm= clean_subm(source_dir='./data/women/women_subm.csv', save_dir = './data/women/women_clean_subm.csv', year = 2016, month = 6, day = 27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## r/femaledatingstrategy\n",
    "Oct 28, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nguye\\AppData\\Local\\Temp\\ipykernel_9716\\1733050532.py:2: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(source_dir)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This df originally has 47385 comments.\n",
      "Pre:16028, Post:31357\n",
      "8186 comments were deleted/removed.\n",
      "Automod posted 2565 comments.\n",
      "Pre: 13485, Post: 23149, Total: 36634\n"
     ]
    }
   ],
   "source": [
    "fds_comm = clean_comments(source_dir='./data/fds/fds_comments.csv',save_dir = './data/fds/fds_clean_comments.csv',day = 28, month = 10, year = 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This df has 2795 submissions.\n",
      "Pre:894, Post:1901\n",
      "1668 submissions has content\n",
      "640 comments were deleted or removed.\n",
      "Automod posted 0 submissions.\n",
      "159 submissions are images pre.\n",
      "432 submissions are images post.\n",
      "Pre: 432, Post: 596, Total: 1028\n"
     ]
    }
   ],
   "source": [
    "fds_subm = clean_subm(source_dir='./data/fds/fds_subm.csv',save_dir = './data/fds/fds_clean_subm.csv',day = 28, month = 10, year = 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control group for r/femaledatingstrategy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## r/WitchesVSPatriarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This df originally has 36452 comments.\n",
      "Pre:16979, Post:19473\n",
      "2269 comments were deleted/removed.\n",
      "Automod posted 8 comments.\n",
      "Pre: 16017, Post: 18158, Total: 34175\n"
     ]
    }
   ],
   "source": [
    "wvsp = clean_comments(source_dir='./data/control-fds/wvsp.csv',save_dir='./data/Control/wvsp_clean.csv',year = 2019, month = 10, day = 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## r/TwoXChromosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This df originally has 160591 comments.\n",
      "Pre:76970, Post:83621\n",
      "23553 comments were deleted/removed.\n",
      "Automod posted 73 comments.\n",
      "Pre: 67713, Post: 69252, Total: 136965\n"
     ]
    }
   ],
   "source": [
    "twox = clean_comments(source_dir = './data/control-fds/TwoXChromosomes.csv',save_dir = './data/Concontrol-fdstrol/TwoXChromosomes_clean.csv',year = 2019, month = 10, day = 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## r/feminism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This df originally has 14471 comments.\n",
      "Pre:6913, Post:7558\n",
      "4728 comments were deleted/removed.\n",
      "Automod posted 0 comments.\n",
      "Pre: 4529, Post: 5214, Total: 9743\n"
     ]
    }
   ],
   "source": [
    "fem = clean_comments(source_dir = './data/control-fds/feminism.csv',save_dir = './data/Control/feminism_clean.csv',year = 2019, month = 10, day = 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This df originally has 228993 comments.\n",
      "Pre:113502, Post:115491\n",
      "43192 comments were deleted/removed.\n",
      "Automod posted 398 comments.\n",
      "Pre: 93202, Post: 92201, Total: 185403\n"
     ]
    }
   ],
   "source": [
    "## r/MGTOW\n",
    "mgtow = clean_comments(source_dir = './data/control-fds/MGTOW.csv',save_dir = './data/Control/MGTOW_clean.csv',year = 2019, month = 10, day = 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## r/TheRedPill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This df originally has 22283 comments.\n",
      "Pre:11427, Post:10856\n",
      "2542 comments were deleted/removed.\n",
      "Automod posted 677 comments.\n",
      "Pre: 9737, Post: 9327, Total: 19064\n"
     ]
    }
   ],
   "source": [
    "trd = clean_comments(source_dir='./data/control-fds/TheRedPill.csv',save_dir='./data/Control/TheRedPill_clean.csv', year = 2019, month = 10, day = 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This df originally has 46727 comments.\n",
      "Pre:23458, Post:23269\n",
      "1021 comments were deleted/removed.\n",
      "Automod posted 0 comments.\n",
      "Pre: 22850, Post: 22856, Total: 45706\n"
     ]
    }
   ],
   "source": [
    "trollX = clean_comments(source_dir='./data/control-fds/trollX.csv',save_dir='./data/control-fds/trollX_clean.csv', year = 2019, month = 10, day = 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual as reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fds_comments_after = pd.read_csv('./data/fds_comments_after.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only choose what relevant\n",
    "fds_comments_after_df = fds_comments_after[['body','author','created_utc','retrieved_on','permalink','parent_id','subreddit','score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change epoch time to human time \n",
    "fds_comments_after_df['created_utc'] = pd.to_datetime(fds_comments_after_df['created_utc'], unit='s')\n",
    "fds_comments_after_df['retrieved_on'] = pd.to_datetime(fds_comments_after_df['retrieved_on'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get month (Oct and Nov)\n",
    "# Two conditions, to check if data is what I want\n",
    "fds_comments_after_df[(fds_comments_after_df['created_utc'].dt.month == 10) & (fds_comments_after_df['created_utc'].dt.day == 28)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get month (Oct and Nov) - 1 mo after bot; Dec - 2 mo after bot; Jan - 3 mo after bot\n",
    "fds_comments_after_1mo_df = fds_comments_after_df[(fds_comments_after_df['created_utc'].dt.month == 10) | (fds_comments_after_df['created_utc'].dt.month == 11)]\n",
    "fds_comments_after_2mo_df = fds_comments_after_df[fds_comments_after_df['created_utc'].dt.month == 12]\n",
    "fds_comments_after_3mo_df = fds_comments_after_df[fds_comments_after_df['created_utc'].dt.month == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save datasets\n",
    "fds_comments_after_1mo_df.to_csv('fds_comments_after_1mo.csv')\n",
    "fds_comments_after_2mo_df.to_csv('fds_comments_after_2mo.csv')\n",
    "fds_comments_after_3mo_df.to_csv('fds_comments_after_3mo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before comments\n",
    "Replicate the steps above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fds_comments_before = pd.read_csv('fds_comments_before.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fds_comments_before_df = fds_comments_before[['body','author','created_utc','retrieved_on','permalink','parent_id','subreddit','score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change epoch time to human time \n",
    "fds_comments_before_df['created_utc'] = pd.to_datetime(fds_comments_before_df['created_utc'], unit='s')\n",
    "fds_comments_before_df['retrieved_on'] = pd.to_datetime(fds_comments_before_df['retrieved_on'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the date range is what I want\n",
    "fds_comments_before_df[(fds_comments_before_df['created_utc'].dt.month == 10) & (fds_comments_before_df['created_utc'].dt.day == 27)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get month\n",
    "fds_comments_before_1mo_df = fds_comments_after_df[fds_comments_after_df['created_utc'].dt.month == 10]\n",
    "fds_comments_before_2mo_df = fds_comments_after_df[fds_comments_after_df['created_utc'].dt.month == 9]\n",
    "fds_comments_before_3mo_df = fds_comments_after_df[fds_comments_after_df['created_utc'].dt.month == 8]\n",
    "fds_comments_before_4mo_df = fds_comments_after_df[fds_comments_after_df['created_utc'].dt.month == 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save datasets\n",
    "fds_comments_before_1mo_df.to_csv('fds_comments_before_1mo.csv')\n",
    "fds_comments_before_2mo_df.to_csv('fds_comments_before_2mo.csv')\n",
    "fds_comments_before_3mo_df.to_csv('fds_comments_before_3mo.csv')\n",
    "fds_comments_before_4mo_df.to_csv('fds_comments_before_4mo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fds_sub_b4 = pd.read_csv('./data/fds_submissions_before.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fds_sub_b4_df = fds_sub_b4[['author','author_flair_text','created_utc','retrieved_on','domain','full_link','id','is_reddit_media_domain','permalink','is_video','locked','num_comments','subreddit','subreddit_id','score','selftext','subreddit_subscribers','title','total_awards_received','updated_utc','removed_by','poll_data']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to human date\n",
    "fds_sub_b4_df['created_utc'] = pd.to_datetime(fds_sub_b4_df['created_utc'], unit='s')\n",
    "fds_sub_b4_df['retrieved_on'] = pd.to_datetime(fds_sub_b4_df['retrieved_on'], unit='s')\n",
    "fds_sub_b4_df['updated_utc'] = pd.to_datetime(fds_sub_b4_df['updated_utc'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the date range is what I want\n",
    "fds_sub_b4_df[(fds_sub_b4_df['created_utc'].dt.month == 7) & (fds_sub_b4_df['created_utc'].dt.day == 27)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get month\n",
    "fds_subm_before_1mo_df = fds_sub_b4_df[fds_sub_b4_df['created_utc'].dt.month == 10]\n",
    "fds_subm_before_2mo_df = fds_sub_b4_df[fds_sub_b4_df['created_utc'].dt.month == 9]\n",
    "fds_subm_before_3mo_df = fds_sub_b4_df[fds_sub_b4_df['created_utc'].dt.month == 8]\n",
    "fds_subm_before_4mo_df = fds_sub_b4_df[fds_sub_b4_df['created_utc'].dt.month == 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save datasets\n",
    "fds_subm_before_1mo_df.to_csv('./data/fds_subm_before_1mo.csv')\n",
    "fds_subm_before_2mo_df.to_csv('./data/fds_subm_before_2mo.csv')\n",
    "fds_subm_before_3mo_df.to_csv('./data/fds_subm_before_3mo.csv')\n",
    "fds_subm_before_4mo_df.to_csv('./data/fds_subm_before_4mo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submissions after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fds_sub_after = pd.read_csv('./data/fds_submissions_after.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fds_sub_after_df = fds_sub_after[['author','author_flair_text','created_utc','retrieved_on','domain','full_link','id','is_reddit_media_domain','permalink','is_video','locked','num_comments','subreddit','subreddit_id','score','selftext','subreddit_subscribers','title','total_awards_received','updated_utc','removed_by']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to human date\n",
    "fds_sub_after_df['created_utc'] = pd.to_datetime(fds_sub_after_df['created_utc'], unit='s')\n",
    "fds_sub_after_df['retrieved_on'] = pd.to_datetime(fds_sub_after_df['retrieved_on'], unit='s')\n",
    "fds_sub_after_df['updated_utc'] = pd.to_datetime(fds_sub_after_df['updated_utc'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fds_sub_after_df[(fds_sub_after_df['created_utc'].dt.month == 10) & (fds_sub_after_df['created_utc'].dt.day == 28)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get month\n",
    "fds_subm_after_1mo_df = fds_sub_after_df[(fds_sub_after_df['created_utc'].dt.month == 11) &(fds_sub_after_df['created_utc'].dt.month == 10)]\n",
    "fds_subm_after_2mo_df = fds_sub_after_df[fds_sub_after_df['created_utc'].dt.month == 12]\n",
    "fds_subm_after_3mo_df = fds_sub_after_df[fds_sub_after_df['created_utc'].dt.month == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save datasets\n",
    "fds_subm_after_1mo_df.to_csv('./data/fds_subm_after_1mo.csv')\n",
    "fds_subm_after_2mo_df.to_csv('./data/fds_subm_after_2mo.csv')\n",
    "fds_subm_after_3mo_df.to_csv('./data/fds_subm_after_3mo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Analysis\n",
    "For Comments: Deleted comments\n",
    "\n",
    "For Submissions: Deleted submissions, non-text content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import BEFORE data. Dataset already in this notebook\n",
    "fds_b4_1mo =  pd.read_csv('./data/fds_comments_before_1mo.csv')\n",
    "\n",
    "#Number of deleted and remove\n",
    "len(fds_b4_1mo[(fds_b4_1mo['body'] == '[deleted]') | (fds_b4_1mo['body'] == '[removed]')])/len(fds_b4_1mo)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import AFTER data\n",
    "fds_aft_1mo =  pd.read_csv('./data/fds_comments_after_1mo.csv')\n",
    "\n",
    "#Number of deleted and remove\n",
    "len(fds_aft_1mo[(fds_aft_1mo['body'] == '[deleted]') | (fds_aft_1mo['body'] == '[removed]')])/len(fds_aft_1mo)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of deleted commments - Other months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import BEFORE data - Jul\n",
    "fds_jul =  pd.read_csv('./data/fds_comments_before_4mo.csv')\n",
    "\n",
    "#Number of deleted and remove\n",
    "len(fds_jul[(fds_jul['body'] == '[deleted]') | (fds_jul['body'] == '[removed]')])/len(fds_jul)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import BEFORE data - Aug\n",
    "fds_aug =  pd.read_csv('./data/fds_comments_before_3mo.csv')\n",
    "\n",
    "#Number of deleted and remove\n",
    "len(fds_aug[(fds_aug['body'] == '[deleted]') | (fds_aug['body'] == '[removed]')])/len(fds_aug)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import BEFORE data - Sep\n",
    "fds_sep =  pd.read_csv('./data/fds_comments_before_2mo.csv')\n",
    "\n",
    "#Number of deleted and remove\n",
    "len(fds_sep[(fds_sep['body'] == '[deleted]') | (fds_sep['body'] == '[removed]')])/len(fds_sep)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import AFTER data - Dec\n",
    "fds_dec =  pd.read_csv('./data/fds_comments_after_2mo.csv')\n",
    "\n",
    "#Number of deleted and remove\n",
    "len(fds_dec[(fds_dec['body'] == '[deleted]') | (fds_dec['body'] == '[removed]')])/len(fds_dec)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import AFTER data - Jan\n",
    "fds_jan =  pd.read_csv('./data/fds_comments_after_3mo.csv')\n",
    "\n",
    "#Number of deleted and remove\n",
    "len(fds_jan[(fds_jan['body'] == '[deleted]') | (fds_jan['body'] == '[removed]')])/len(fds_jan)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redditbots",
   "language": "python",
   "name": "redditbots"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b968dbae3bdbf6d1cce176bc5e29e5d5d95fd8d61e6698691c9965b2a654e88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
