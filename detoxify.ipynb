{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nguye\\anaconda3\\envs\\redditbots\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from detoxify import Detoxify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as sts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# personal library\n",
    "from my_detoxify import detox #, detox_loop, flag_base, flag_unbiased, clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each model takes in either a string or a list of strings\n",
    "results = Detoxify('original').predict('example text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Detoxify('unbiased').predict(['example text 1','example text 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Detoxify('multilingual').predict(['example text','exemple de texte','texto de ejemplo','testo di esempio','texto de exemplo','örnek metin','пример текста'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to specify the device the model will be allocated on (defaults to cpu), accepts any torch.device input\n",
    "model = Detoxify('original', device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results).round(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Toxicity Mean\n",
    "results_df['toxicity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all column Mean\n",
    "results_df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detox_loop(df,model):\n",
    "    detox = Detoxify(model, device='cuda')\n",
    "    i = 0\n",
    "    n = len(df)\n",
    "    df_res = pd.DataFrame()\n",
    "    while i < n:\n",
    "        res = detox.predict(df[i:i+100])\n",
    "        f = pd.DataFrame(res,df[i:i+100]).round(5)\n",
    "        df_res = pd.concat([df_res,f])\n",
    "        i = i + 100\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_base(df_res,thresh):\n",
    "    [float(i) for i in thresh]\n",
    "    df_res['toxicity_flag'] = np.where(df_res['toxicity']>thresh[0],1,0)\n",
    "    df_res['severe_toxicity_flag'] = np.where(df_res['severe_toxicity']>thresh[1],1,0)\n",
    "    df_res['obscene_flag'] = np.where(df_res['obscene']>thresh[2],1,0)\n",
    "    df_res['threat_flag'] = np.where(df_res['threat']>thresh[3],1,0)\n",
    "    df_res['insult_flag'] = np.where(df_res['insult']>thresh[4],1,0)\n",
    "    df_res['identity_attack_flag'] = np.where(df_res['identity_attack']>thresh[5],1,0)\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_unbiased(df_res,thresh):\n",
    "    [float(i) for i in thresh]\n",
    "    df_res['toxicity_flag'] = np.where(df_res['toxicity']>thresh[0],1,0)\n",
    "    df_res['severe_toxicity_flag'] = np.where(df_res['severe_toxicity']>thresh[1],1,0)\n",
    "    df_res['obscene_flag'] = np.where(df_res['obscene']>thresh[2],1,0)\n",
    "    df_res['threat_flag'] = np.where(df_res['threat']>thresh[3],1,0)\n",
    "    df_res['insult_flag'] = np.where(df_res['insult']>thresh[4],1,0)\n",
    "    df_res['identity_attack_flag'] = np.where(df_res['identity_attack']>thresh[5],1,0)\n",
    "    df_res['sexual_explicit_flag'] = np.where(df_res['sexual_explicit']>thresh[6],1,0)\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df,model,thresh, print_res):\n",
    "    df=list(df['body'].values.flatten())\n",
    "    res = detox_loop(df=df,model=model)\n",
    "    \n",
    "    if model == 'original':\n",
    "        res = flag_base(df_res=res, thresh = thresh)\n",
    "    else:\n",
    "        res = flag_unbiased(df_res=res, thresh = thresh)\n",
    "    \n",
    "    if print_res == True:\n",
    "        df_mean = res.mean()\n",
    "        return res,df_mean\n",
    "    else:\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detox(source_dir,model, thresh, print_res, save_dir):\n",
    "    #keeping separate pre-post list\n",
    "    df = pd.read_csv(source_dir)\n",
    "    df_pre = df[df['post']==0]\n",
    "    df_post = df[df['post']==1]\n",
    " \n",
    "    #pre\n",
    "    if print_res == True:\n",
    "        pre_res,pre_mean = clean(df=df_pre,model=model, thresh=thresh, print_res = True)\n",
    "        print(f'Pre: {pre_mean}')\n",
    "    else:\n",
    "        pre_res = clean(df=df_pre,model=model, thresh=thresh, print_res = False)\n",
    "    pre_res = pd.concat([df_pre.reset_index(drop=True),pre_res.reset_index(drop=True)], axis = 1)\n",
    "    #post\n",
    "    if print_res == True:\n",
    "        post_res,post_mean = clean(df=df_post,model=model, thresh=thresh, print_res = True)\n",
    "        print(f'Pre: {post_mean}')\n",
    "    else:\n",
    "        post_res = clean(df=df_post,model=model, thresh=thresh, print_res = False)\n",
    "    post_res = pd.concat([df_post.reset_index(drop=True),post_res.reset_index(drop=True)], axis = 1)\n",
    "\n",
    "    if save_dir != False:\n",
    "        pre_res['post'] = 0\n",
    "        post_res['post'] = 1\n",
    "        res = pd.concat([pre_res,post_res], ignore_index= True)\n",
    "        res.to_csv(save_dir,encoding = 'utf-8-sig')\n",
    "\n",
    "    return pre_res,post_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(pre_res,post_res,model):\n",
    "    tox = sts.ttest_ind(pre_res['toxicity'], post_res['toxicity'])\n",
    "    print(f'Toxicity: {tox}')\n",
    "\n",
    "    sev_tox = sts.ttest_ind(pre_res['severe_toxicity'], post_res['severe_toxicity'])\n",
    "    print(f'Severe Toxicity: {sev_tox}')\n",
    "\n",
    "    obscene = sts.ttest_ind(pre_res['obscene'], post_res['obscene'])\n",
    "    print(f'Obscene: {obscene}')\n",
    "\n",
    "    threat = sts.ttest_ind(pre_res['threat'], post_res['threat'])\n",
    "    print(f'Threat: {threat}')\n",
    "\n",
    "    insult = sts.ttest_ind(pre_res['insult'], post_res['insult'])\n",
    "    print(f'Insult: {insult}')\n",
    "\n",
    "    identity = sts.ttest_ind(pre_res['identity_attack'], post_res['identity_attack'])\n",
    "    print(f'Identity Attack: {identity}')\n",
    "\n",
    "    tox_f = sts.ttest_ind(pre_res['toxicity_flag'], post_res['toxicity_flag'])\n",
    "    print(f'Toxicity Flag: {tox_f}')\n",
    "\n",
    "    sev_tox_f = sts.ttest_ind(pre_res['severe_toxicity_flag'], post_res['severe_toxicity_flag'])\n",
    "    print(f'Severe Toxicity Flag: {sev_tox_f}')\n",
    "\n",
    "    obscene_f = sts.ttest_ind(pre_res['obscene_flag'], post_res['obscene_flag'])\n",
    "    print(f'Obscene Flag: {obscene_f}')\n",
    "\n",
    "    threat_f = sts.ttest_ind(pre_res['threat_flag'], post_res['threat_flag'])\n",
    "    print(f'Threat Flag: {threat_f}')\n",
    "\n",
    "    insult_f = sts.ttest_ind(pre_res['insult'], post_res['insult'])\n",
    "    print(f'Insult Flag: {insult_f}')\n",
    "\n",
    "    identity_f = sts.ttest_ind(pre_res['identity_attack_flag'], post_res['identity_attack_flag'])\n",
    "    print(f'Identity Attack Flag: {identity}')\n",
    "    \n",
    "    if model == 'unbiased':\n",
    "        sexual_exp = sts.ttest_ind(pre_res['sexual_explicit'], post_res['sexual_explicit'])\n",
    "        print(f'Sexual Explicit: {sexual_exp}')\n",
    "\n",
    "        sexual_exp_f = sts.ttest_ind(pre_res['sexual_explicit_flag'], post_res['sexual_explicit_flag'])\n",
    "        print(f'Sexual Explicit Flag: {sexual_exp_f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## r/femaledatingstrategy as focal community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = [.5,.5,.5,.5,.5,.5,.5]\n",
    "thresh = [float(i) for i in thresh]\n",
    "fds_base_pre,fds_base_post = detox(source_dir= './data/fds/fds_clean_comments.csv', model = 'original',thresh = thresh, print_res = False, save_dir =  './data/fds/fds_res.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare\n",
    "compare(fds_base_pre,fds_base_post, model = 'original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control for FDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### r/Feminism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = [.5,.5,.5,.5,.5,.5]\n",
    "thresh = [float(i) for i in thresh]\n",
    "feminism_base_pre,feminism_base_post = detox(source_dir='./data/control-fds/feminism_clean.csv', model = 'original',thresh = thresh, print_res = False, save_dir = './data/control-fds/feminism_res.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### r/TwoXChromosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = [.5,.5,.5,.5,.5,.5,.5]\n",
    "thresh = [float(i) for i in thresh]\n",
    "twoX_base_pre,twoX_base_post = detox(source_dir='./data/control-fds/TwoXChromosomes_clean.csv', model = 'original',thresh = thresh, print_res = False, save_dir = './data/control-fds/twoX_res.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## r/WitchesVSPatriarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = [.5,.5,.5,.5,.5,.5,.5]\n",
    "thresh = [float(i) for i in thresh]\n",
    "wvsp_base_pre,wvsp_base_post = detox(source_dir='./data/control-fds/wvsp_clean.csv', model = 'original',thresh = thresh, print_res = False, save_dir = './data/control-fds/wvsp_res.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## r/MGTOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = [.5,.5,.5,.5,.5,.5,.5]\n",
    "thresh = [float(i) for i in thresh]\n",
    "mgtow_base_pre,mgtow_base_post = detox(source_dir='./data/control-fds/MGTOW_clean.csv', model = 'original',thresh = thresh, print_res = False, save_dir = './data/control-fds/MGTOW_res.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## r/TheRedPill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = [.5,.5,.5,.5,.5,.5,.5]\n",
    "thresh = [float(i) for i in thresh]\n",
    "trp_base_pre,trp_base_post = detox(source_dir='./data/control-fds/TheRedPill_clean.csv', model = 'original',thresh = thresh, print_res = False, save_dir = './data/control-fds/TheRedPill_res.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## r/TrollXChromosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = [.5,.5,.5,.5,.5,.5,.5]\n",
    "thresh = [float(i) for i in thresh]\n",
    "trollX_base_pre, trollX_base_post = detox(source_dir='./data/control-fds/trollX_clean.csv', model = 'original',thresh = thresh, print_res = False, save_dir = './data/control-fds/trollX_res.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual for reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import BEFORE data\n",
    "fds_b4_1mo =  pd.read_csv('./data/fds_comments_before_1mo.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leave out all 'removed' and 'deleted' comments\n",
    "fds_b4_1mo_df = fds_b4_1mo[(fds_b4_1mo['body'] != '[deleted]') & (fds_b4_1mo['body'] != '[removed]') & (fds_b4_1mo['author'] != 'AutoModerator')]\n",
    "\n",
    "#Flatten to list of string\n",
    "fds_b4_1mo_body = list(fds_b4_1mo_df['body'].values.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import AFTER data\n",
    "fds_aft_1mo =  pd.read_csv('./data/fds_comments_after_1mo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leave out all 'removed' and 'deleted' comments\n",
    "fds_aft_1mo_df = fds_aft_1mo[(fds_aft_1mo['body'] != '[deleted]') & (fds_aft_1mo['body'] != '[removed]') & (fds_aft_1mo['author'] !='AutoModerator')]\n",
    "\n",
    "#Flatten to list of string\n",
    "fds_aft_1mo_body = list(fds_aft_1mo_df['body'].values.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Submission\n",
    "Concerns:\n",
    "- Structure of a submission: title, body (`self_text`), images/video link (`domain`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import SUBMISSION BEFORE\n",
    "fds_b4_1mo_sub = pd.read_csv('./data/fds_subm_before_1mo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of no content submissions\n",
    "fds_b4_1mo_sub['selftext'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percentage of no content submissions\n",
    "fds_b4_1mo_sub['selftext'].isnull().sum()/len(fds_b4_1mo_sub['selftext'] != '[removed]')*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condition: domain = i.reddit.it OR imugur AND selftext = \"\"\n",
    "len(fds_b4_1mo_sub[((fds_b4_1mo_sub['domain'] == 'i.redd.it') | (fds_b4_1mo_sub['domain'] == 'i.imgur.com') |  (fds_b4_1mo_sub['domain'] == 'imgur.com'))  & fds_b4_1mo_sub['selftext'].isnull()]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condition: domain = i.reddit.it OR imugur. So basically they are the same.\n",
    "len(fds_b4_1mo_sub[(fds_b4_1mo_sub['domain'] == 'i.redd.it') | (fds_b4_1mo_sub['domain'] == 'i.imgur.com') |  (fds_b4_1mo_sub['domain'] == 'imgur.com')]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of image submissions\n",
    "len(fds_b4_1mo_sub[(fds_b4_1mo_sub['domain'] == 'self.FemaleDatingStrategy')]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fds_b4_1mo_sub_df = fds_b4_1mo_sub[fds_b4_1mo_sub['selftext']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save only submissions has written content and not deleted or removed\n",
    "fds_b4_1mo_sub_test = fds_b4_1mo_sub[(fds_b4_1mo_sub['selftext'].astype(bool)) | (fds_b4_1mo_sub['selftext'] == '[removed]')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Model - Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set pre-trained model and run on GPU\n",
    "originalmodel = Detoxify('original', device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the first batch\n",
    "res = originalmodel.predict(fds_b4_1mo_body[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect with body text\n",
    "pd.DataFrame(res,fds_b4_1mo_body[0:100]).round(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "n = len(fds_b4_1mo_body)\n",
    "fds_b4_1mo_body_res_base = pd.DataFrame()\n",
    "while i < n:\n",
    "    res = originalmodel.predict(fds_b4_1mo_body[i:i+100])\n",
    "    f = pd.DataFrame(res,fds_b4_1mo_body_res_base[i:i+100]).round(5)\n",
    "    fds_b4_1mo_body_res_base = pd.concat([fds_b4_1mo_body_res_base,f])\n",
    "    i = i + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add flag to each comments\n",
    "fds_b4_1mo_body_res_base['toxicity_flag'] = np.where(fds_b4_1mo_body_res_base['toxicity']>0.5,1,0)\n",
    "fds_b4_1mo_body_res_base['severe_toxicity_flag'] = np.where(fds_b4_1mo_body_res_base['severe_toxicity']>0.01,1,0)\n",
    "fds_b4_1mo_body_res_base['obscene_flag'] = np.where(fds_b4_1mo_body_res_base['obscene']>0.5,1,0)\n",
    "fds_b4_1mo_body_res_base['threat_flag'] = np.where(fds_b4_1mo_body_res_base['threat']>0.5,1,0)\n",
    "fds_b4_1mo_body_res_base['insult_flag'] = np.where(fds_b4_1mo_body_res_base['insult']>0.5,1,0)\n",
    "fds_b4_1mo_body_res_base['identity_attack_flag'] = np.where(fds_b4_1mo_body_res_base['identity_attack']>0.5,1,0)\n",
    "print(fds_b4_1mo_body_res_base.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "n = len(fds_aft_1mo_body)\n",
    "fds_aft_1mo_body_res_base = pd.DataFrame()\n",
    "while i < n:\n",
    "    res = unbiasedmodel.predict(fds_aft_1mo_body_res_base[i:i+100])\n",
    "    f = pd.DataFrame(res,fds_aft_1mo_body_res_base[i:i+100]).round(5)\n",
    "    fds_aft_1mo_body_res_base = pd.concat([fds_aft_1mo_body_res_base,f])\n",
    "    i = i + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add flag to each comments\n",
    "fds_aft_1mo_body_res_base['toxicity_flag'] = np.where(fds_aft_1mo_body_res_base['toxicity']>0.5,1,0)\n",
    "fds_aft_1mo_body_res_base['severe_toxicity_flag'] = np.where(fds_aft_1mo_body_res_base['severe_toxicity']>0.01,1,0)\n",
    "fds_aft_1mo_body_res_base['obscene_flag'] = np.where(fds_aft_1mo_body_res_base['obscene']>0.5,1,0)\n",
    "fds_aft_1mo_body_res_base['threat_flag'] = np.where(fds_aft_1mo_body_res_base['threat']>0.0035,1,0)\n",
    "fds_aft_1mo_body_res_base['insult_flag'] = np.where(fds_aft_1mo_body_res_base['insult']>0.5,1,0)\n",
    "fds_aft_1mo_body_res_base['identity_attack_flag'] = np.where(fds_aft_1mo_body_res_base['identity_attack']>0.5,1,0)\n",
    "fds_aft_1mo_body_res_base['sexual_explicit_flag'] = np.where(fds_aft_1mo_body_res_base['sexual_explicit']>0.5,1,0)\n",
    "print(fds_aft_1mo_body_res_base.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prelim Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as sts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fds_aft_1mo_body_res_base['post'] = 1\n",
    "fds_b4_1mo_body_res_base['post'] = 0\n",
    "fds = pd.concat([fds_aft_1mo_body_res_base, fds_b4_1mo_body_res_base])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.ttest_ind(fds_aft_1mo_body_res_base['toxicity'], fds_aft_1mo_body_res_base['toxicity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.ttest_ind(fds_aft_1mo_body_res_base['severe_toxicity'], fds_aft_1mo_body_res_base['severe_toxicity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.ttest_ind(fds_aft_1mo_body_res_base['obscene'], fds_aft_1mo_body_res_base['obscene'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.ttest_ind(fds_aft_1mo_body_res_base['threat'], fds_aft_1mo_body_res_base['threat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.ttest_ind(fds_aft_1mo_body_res_base['insult'], fds_aft_1mo_body_res_base['insult'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.ttest_ind(fds_aft_1mo_body_res_base['identity_attack'], fds_aft_1mo_body_res_base['identity_attack'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.ttest_ind(fds_aft_1mo_body_res_base['toxicity_flag'], fds_aft_1mo_body_res_base['toxicity_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.ttest_ind(fds_aft_1mo_body_res_base['severe_toxicity_flag'], fds_aft_1mo_body_res_base['severe_toxicity_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.ttest_ind(fds_aft_1mo_body_res_base['obscene_flag'], fds_aft_1mo_body_res_base['obscene_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.ttest_ind(fds_aft_1mo_body_res_base['threat_flag'], fds_aft_1mo_body_res_base['threat_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.ttest_ind(fds_aft_1mo_body_res_base['insult_flag'], fds_aft_1mo_body_res_base['insult_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.ttest_ind(fds_aft_1mo_body_res_base['identity_attack_flag'], fds_aft_1mo_body_res_base['identity_attack_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.ttest_ind(fds_aft_1mo_body_res_base['sexual_explicit_flag'], fds_aft_1mo_body_res_base['sexual_explicit_flag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Model - Unbiased Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set pre-trained model and run o\n",
    "unbiasedmodel = Detoxify('unbiased', device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before 1 month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "n = len(fds_b4_1mo_body)\n",
    "fds_b4_1mo_body_res = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while i < n:\n",
    "    res = unbiasedmodel.predict(fds_b4_1mo_body[i:i+100])\n",
    "    f = pd.DataFrame(res,fds_b4_1mo_body[i:i+100]).round(5)\n",
    "    fds_b4_1mo_body_res = pd.concat([fds_b4_1mo_body_res,f])\n",
    "    i = i + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add flag to each comments\n",
    "fds_b4_1mo_body_res['toxicity_flag'] = np.where(fds_b4_1mo_body_res['toxicity']>0.5,1,0)\n",
    "fds_b4_1mo_body_res['severe_toxicity_flag'] = np.where(fds_b4_1mo_body_res['severe_toxicity']>0.01,1,0)\n",
    "fds_b4_1mo_body_res['obscene_flag'] = np.where(fds_b4_1mo_body_res['obscene']>0.5,1,0)\n",
    "fds_b4_1mo_body_res['threat_flag'] = np.where(fds_b4_1mo_body_res['threat']>0.5,1,0)\n",
    "fds_b4_1mo_body_res['insult_flag'] = np.where(fds_b4_1mo_body_res['insult']>0.5,1,0)\n",
    "fds_b4_1mo_body_res['identity_attack_flag'] = np.where(fds_b4_1mo_body_res['identity_attack']>0.5,1,0)\n",
    "fds_b4_1mo_body_res['sexual_explicit_flag'] = np.where(fds_b4_1mo_body_res['sexual_explicit']>0.5,1,0)\n",
    "print(fds_b4_1mo_body_res.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After 1 month comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "n = len(fds_aft_1mo_body)\n",
    "fds_aft_1mo_body_res = pd.DataFrame()\n",
    "while i < n:\n",
    "    res = unbiasedmodel.predict(fds_aft_1mo_body[i:i+100])\n",
    "    f = pd.DataFrame(res,fds_aft_1mo_body[i:i+100]).round(5)\n",
    "    fds_aft_1mo_body_res = pd.concat([fds_aft_1mo_body_res,f])\n",
    "    i = i + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add flag to each comments\n",
    "fds_aft_1mo_body_res['toxicity_flag'] = np.where(fds_aft_1mo_body_res['toxicity']>0.5,1,0)\n",
    "fds_aft_1mo_body_res['severe_toxicity_flag'] = np.where(fds_aft_1mo_body_res['severe_toxicity']>0.01,1,0)\n",
    "fds_aft_1mo_body_res['obscene_flag'] = np.where(fds_aft_1mo_body_res['obscene']>0.5,1,0)\n",
    "fds_aft_1mo_body_res['threat_flag'] = np.where(fds_aft_1mo_body_res['threat']>0.0035,1,0)\n",
    "fds_aft_1mo_body_res['insult_flag'] = np.where(fds_aft_1mo_body_res['insult']>0.5,1,0)\n",
    "fds_aft_1mo_body_res['identity_attack_flag'] = np.where(fds_aft_1mo_body_res['identity_attack']>0.5,1,0)\n",
    "fds_aft_1mo_body_res['sexual_explicit_flag'] = np.where(fds_aft_1mo_body_res['sexual_explicit']>0.5,1,0)\n",
    "print(fds_aft_1mo_body_res.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score Difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prelim regression - 1 mo before and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fds_aft_1mo_body_res['post'] = 1\n",
    "fds_b4_1mo_body_res['post'] = 0\n",
    "fds = pd.concat([fds_aft_1mo_body_res, fds_b4_1mo_body_res])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.ttest_ind(fds_aft_1mo_body_res['toxicity'], fds_b4_1mo_body_res['toxicity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.ttest_ind(fds_aft_1mo_body_res['severe_toxicity'], fds_b4_1mo_body_res['severe_toxicity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.ttest_ind(fds_aft_1mo_body_res['obscene'], fds_b4_1mo_body_res['obscene'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.ttest_ind(fds_aft_1mo_body_res['threat'], fds_b4_1mo_body_res['threat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.ttest_ind(fds_aft_1mo_body_res['insult'], fds_b4_1mo_body_res['insult'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.ttest_ind(fds_aft_1mo_body_res['identity_attack'], fds_b4_1mo_body_res['identity_attack'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.ttest_ind(fds_aft_1mo_body_res['sexual_explicit'], fds_b4_1mo_body_res['sexual_explicit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perc Flag Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.ttest_ind(fds_aft_1mo_body_res['toxicity_flag'], fds_b4_1mo_body_res['toxicity_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.ttest_ind(fds_aft_1mo_body_res['severe_toxicity_flag'], fds_b4_1mo_body_res['severe_toxicity_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.ttest_ind(fds_aft_1mo_body_res['obscene_flag'], fds_b4_1mo_body_res['obscene_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.ttest_ind(fds_aft_1mo_body_res['threat_flag'], fds_b4_1mo_body_res['threat_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.ttest_ind(fds_aft_1mo_body_res['insult_flag'], fds_b4_1mo_body_res['insult_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.ttest_ind(fds_aft_1mo_body_res['identity_attack_flag'], fds_b4_1mo_body_res['identity_attack_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts.ttest_ind(fds_aft_1mo_body_res['sexual_explicit_flag'], fds_b4_1mo_body_res['sexual_explicit_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test =pd.read_csv('./data/Control/feminism_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_body = list(test[test['post']==1]['body'].values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_extract = test[test['post']==1][0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = Detoxify('unbiased',device = 'cuda').predict(test_extract['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res_df = pd.DataFrame(test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_extract_df = pd.DataFrame(test_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([test_res_df, test_extract])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('redditbots')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b2a55f9055c2400523b349fd3301d5efeb6493fd652ed128c88c237df22f590"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
