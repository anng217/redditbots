{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pmaw import PushshiftAPI\n",
    "api = PushshiftAPI()\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import praw\n",
    "import time\n",
    "#from redditbots_function import flatten_author, author_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Praw Enhancement\n",
    "reddit = praw.Reddit(\n",
    " client_id='9wXh5oa4cfW07_eUn5Hu3A',\n",
    " client_secret='m3GnhaEvbM5LGCWX3BMghLCatOLN3g',\n",
    " user_agent=f'python: PMAW request enrichment (by u/softyarn)'\n",
    ")\n",
    "api_praw = PushshiftAPI(praw=reddit)\n",
    "# Pmaw\n",
    "api = PushshiftAPI(max_sleep = 60, shards_down_behavior = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epochdate(bot_epoch, duration):\n",
    "    before = int((dt.datetime.fromtimestamp(bot_epoch)+dt.timedelta(days = duration)).timestamp())\n",
    "    after = int((dt.datetime.fromtimestamp(bot_epoch)-dt.timedelta(days = duration)).timestamp())\n",
    "    return before, after\n",
    "def within60days(df, bot_epoch, duration):\n",
    "    before, after = get_epochdate(bot_epoch = bot_epoch, duration = duration)\n",
    "    res = df.loc[(df['created_utc'] >= after) & (df['created_utc'] <= before)]\n",
    "    return res\n",
    "def author_list(df):\n",
    "    nomod = df.loc[(df['author'] != \"AutoModerator\") & (df['author'] != '[deleted]')]\n",
    "    authors = nomod.loc[:,'author']\n",
    "    authors_unique = np.unique(authors)\n",
    "    return authors_unique\n",
    "def author_comments(df, bot_epoch, duration, limit = 10000000000):\n",
    "    before, after = get_epochdate(bot_epoch, duration) \n",
    "    #creating loop so that only 100 authors per praw\n",
    "    tic = time.time()\n",
    "    global res\n",
    "    res = []\n",
    "    authors = author_list(df)\n",
    "    i = 0\n",
    "    while i < len(authors):\n",
    "        j = min(i+2, len(authors))\n",
    "        x = ','.join(authors[i:j])\n",
    "        comments = api.search_comments(author = x, limit = limit, before = before, after = after, filter = ['id', 'banned_at_utc', 'mod_reason_title', 'author', 'created_utc', 'parent_id', 'subreddit_id', 'body'], mem_safe= True)\n",
    "        res += [c for c in comments]\n",
    "        if i%500 == 0:\n",
    "            res_out = pd.DataFrame(res)\n",
    "            res_out.to_csv('author_comments_' + str(i/1000) + '.csv', encoding = 'utf_8_sig')\n",
    "            res = []\n",
    "        i +=2\n",
    "        if i%100 == 0:\n",
    "            time.sleep(1)\n",
    "            print('Time elapsed: ', round(time.time() - tic),' secs, i = ',i+5)\n",
    "    res_out = pd.DataFrame(res)\n",
    "    res_out.to_csv('author_comments_Finale.csv', encoding = 'utf_8_sig')   \n",
    "    return res_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nguye\\AppData\\Local\\Temp\\ipykernel_33000\\3957158027.py:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  fds = pd.read_csv(\"E:/gihub-data/redditbots/fds/fds_comments.csv\")\n"
     ]
    }
   ],
   "source": [
    "fds = pd.read_csv(\"E:/gihub-data/redditbots/fds/fds_comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fds1 = within60days(fds, bot_epoch = 1572234835 , duration = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(author_list(fds1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fds2 = fds1[4400:4774]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed:  713  secs, i =  105\n"
     ]
    }
   ],
   "source": [
    "df_res = author_comments(df = fds2, bot_epoch = 1572234835, duration = 30, limit = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "960f2ae499b536958d588fcafb5f9e40dd995fc898e4b79db932caf22756042a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
